{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/leechilvers/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/leechilvers/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leechilvers/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from enum import Enum\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the positive and negative reviews\n",
    "def get_reviews_in(path):\n",
    "    review_file_pattern = re.compile('\\d+_\\d+.txt')\n",
    "    files = os.listdir(path)\n",
    "    # get the review file names\n",
    "    review_files = [file for file in files if review_file_pattern.match(file)] \n",
    "    # get the content of each review file\n",
    "    reviews = []\n",
    "    for review_file in review_files:\n",
    "        review_file_path = os.path.join(path, review_file)\n",
    "        with open(review_file_path, 'r') as content:\n",
    "            reviews.append(content.read())\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# x data\n",
    "pos_reviews = get_reviews_in('film_reviews/pos')\n",
    "neg_reviews = get_reviews_in('film_reviews/neg')\n",
    "reviews = pos_reviews + neg_reviews\n",
    "\n",
    "# y data\n",
    "pos_labels = [0] * len(pos_reviews)\n",
    "neg_labels = [1] * len(neg_reviews)\n",
    "labels = pos_labels + neg_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train/dev/test splits\n",
    "# 80% train and 20% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.2, random_state=42)\n",
    "# split test into 50% dev and 50% test\n",
    "x_dev, x_test, y_dev, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormTech(Enum):\n",
    "    TF_IDF = 1\n",
    "    FREQ_NORM = 2\n",
    "    PPMI = 3\n",
    "\n",
    "class MyFeatureSelector:\n",
    "    \n",
    "    def selectFeatures(self, reviews, normalisation_technique = NormTech.TF_IDF):\n",
    "         # [[('this', 'is', 'a'), ('is', 'a', 'review'), ('a', 'review', None)]]\n",
    "\n",
    "         # feature selection\n",
    "        if (normalisation_technique == NormTech.TF_IDF):\n",
    "            reviews = self.__tf_idf(reviews)\n",
    "        elif (normalisation_technique == NormTech.FREQ_NORM):\n",
    "            reviews = self.__freq_norm(reviews)\n",
    "        elif (normalisation_technique == NormTech.PPMI):\n",
    "            reviews = self.__ppmi(reviews)\n",
    "            \n",
    "        return reviews\n",
    "    \n",
    "    def __tf_idf(self, reviews):\n",
    "\n",
    "        def __get_tf(term, review):\n",
    "            # tf = number of occurences of the term in the review / number of terms in the review\n",
    "            # TODO: weird object type preventing arithmetic\n",
    "            counter = Counter(review)\n",
    "            print(counter.values)\n",
    "            term_occurances_count = counter[term]\n",
    "            total_terms_count = sum(counter.values)\n",
    "            \n",
    "            return term_occurances_count/total_terms_count\n",
    "        \n",
    "        def __get_idf(term):\n",
    "            # idf = log(number of reviews / number of reviews that contain the term)\n",
    "            reviews_count = len(reviews)\n",
    "            reviews_with_term_count = 1\n",
    "            for review in reviews:\n",
    "                if term in review: reviews_with_term_count += 1\n",
    "            \n",
    "            return math.log(reviews_count/reviews_with_term_count)\n",
    "        \n",
    "        # set (no repeats) of all terms across all documents\n",
    "        terms = set([term for review in reviews for term in review])\n",
    "\n",
    "        # is {term1: [score1, score2], term2: [score1, score2], ...}\n",
    "        tf_map = {term: [__get_tf(term, review) for review in reviews] for term in terms }\n",
    "        # is {term1: score1, term2: score2, ...}\n",
    "        idf_map = {term: __get_idf(term) for term in terms}\n",
    "        # is [{term1: score1, term2: score2, ...}, {term1: score1, term2: score2, ...}]\n",
    "        tf_idf_map = [{term: (tf_map[term][i] * idf_map[term]) for term in terms } for i in range(len(reviews))]\n",
    "\n",
    "        filtered_reviews = []\n",
    "        for i, review_tf_idfs in enumerate(tf_idf_map):\n",
    "            # get the most useful features in a list: [('a', 'useful', 'feature'), ('useful', 'feature', None)]\n",
    "            selected_features = [feature for feature, score in review_tf_idfs.items() if score > 0.01] #TODO: define condition\n",
    "            # modify review so it only has the useful features\n",
    "            filtered_review = [feature for feature in reviews[i] if feature in selected_features]\n",
    "            filtered_reviews.append(filtered_review)\n",
    "        \n",
    "        return filtered_reviews\n",
    "    \n",
    "    def __freq_norm(self, reviews):\n",
    "        return reviews\n",
    "    \n",
    "    def __ppmi(self, reviews):\n",
    "        return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method values of Counter object at 0x7fa53678df90>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-048d33dfb3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mfeature_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyFeatureGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mfeature_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gram_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-048d33dfb3fc>\u001b[0m in \u001b[0;36mgenerateFeatures\u001b[0;34m(self, reviews, is_lemmatisation, is_lowercase, is_stopwords_removed, is_punctuation_removed, n_gram_len, normalisation_technique)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# feature selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfeature_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyFeatureSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalisation_technique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-fa64ed8de817>\u001b[0m in \u001b[0;36mselectFeatures\u001b[0;34m(self, reviews, normalisation_technique)\u001b[0m\n\u001b[1;32m     11\u001b[0m          \u001b[0;31m# feature selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnormalisation_technique\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNormTech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_IDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tf_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnormalisation_technique\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNormTech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFREQ_NORM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__freq_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-fa64ed8de817>\u001b[0m in \u001b[0;36m__tf_idf\u001b[0;34m(self, reviews)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# is {term1: [score1, score2], term2: [score1, score2], ...}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtf_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m__get_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m# is {term1: score1, term2: score2, ...}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0midf_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m__get_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-fa64ed8de817>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# is {term1: [score1, score2], term2: [score1, score2], ...}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtf_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m__get_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m# is {term1: score1, term2: score2, ...}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0midf_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m__get_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-fa64ed8de817>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# is {term1: [score1, score2], term2: [score1, score2], ...}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mtf_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m__get_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m# is {term1: score1, term2: score2, ...}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0midf_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m__get_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-fa64ed8de817>\u001b[0m in \u001b[0;36m__get_tf\u001b[0;34m(term, review)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mterm_occurances_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mtotal_terms_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mterm_occurances_count\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_terms_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyFeatureGenerator:\n",
    "\n",
    "    def generateFeatures(self, reviews, \n",
    "                         is_lemmatisation = True, \n",
    "                         is_lowercase = True, \n",
    "                         is_stopwords_removed = True,\n",
    "                         is_punctuation_removed = False, \n",
    "                         n_gram_len = 1, \n",
    "                         normalisation_technique = NormTech.TF_IDF\n",
    "                         ):\n",
    "        # tokenise each review: ['this', 'is', 'a', 'review']\n",
    "        reviews = self.__tokenise(reviews, is_punctuation_removed, is_stopwords_removed, is_lowercase)\n",
    "\n",
    "        # do lemmatisation or stemming: ['this', 'is', 'a', 'review']\n",
    "        reviews = self.__lemmatise(reviews) if is_lemmatisation else self.__stem(reviews)\n",
    "\n",
    "        # generate n_grams: [[('this', 'is', 'a'), ('is', 'a', 'review'), ('a', 'review', None)]]\n",
    "        reviews = self.__n_gram(reviews, n_gram_len)\n",
    "\n",
    "        # feature selection\n",
    "        feature_selector = MyFeatureSelector()\n",
    "        reviews = feature_selector.selectFeatures(reviews, normalisation_technique)\n",
    "\n",
    "        return reviews\n",
    "\n",
    "    def __tokenise(self, reviews, is_punctuation_removed, is_stopwords_removed, is_lowercase):\n",
    "        tokenised_reviews = []\n",
    "        # tokenise each review using nltk\n",
    "        remove_punc_tokeniser = nltk.RegexpTokenizer('\\w+')\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "        for review in reviews:\n",
    "            # generate tokens with/out punctuation \n",
    "            tokens = remove_punc_tokeniser.tokenize(review) if (is_punctuation_removed) else nltk.word_tokenize(review)\n",
    "            tokenised_review = []\n",
    "            for token in tokens:\n",
    "                # ignoring stopwords\n",
    "                if (is_stopwords_removed and token.lower() in stop_words):\n",
    "                        continue\n",
    "                \n",
    "                # converting to lowercase\n",
    "                result_token = token.lower() if (is_lowercase) else token\n",
    "                \n",
    "                tokenised_review.append(result_token)\n",
    "            tokenised_reviews.append(tokenised_review)\n",
    "        \n",
    "        return tokenised_reviews\n",
    "                        \n",
    "    def __lemmatise(self, reviews):\n",
    "        lemmatised_reviews = []\n",
    "        # do lemmatisation on tokenised reviews\n",
    "        lemmatiser = nltk.WordNetLemmatizer()\n",
    "        for review in reviews:\n",
    "            # review is ['a', 'list', 'of', 'words']\n",
    "            lemmatised_reviews.append([lemmatiser.lemmatize(token) for token in review])\n",
    "        \n",
    "        return lemmatised_reviews\n",
    "    \n",
    "    def __stem(self, reviews):\n",
    "        stemmed_reviews = []\n",
    "        # do stemming on tokenised reviews\n",
    "        stemmer = nltk.PorterStemmer()\n",
    "        for review in reviews:\n",
    "            # review is ['a', 'list', 'of', 'words']\n",
    "            stemmed_reviews.append([stemmer.stem(token) for token in review])\n",
    "        \n",
    "        return stemmed_reviews\n",
    "    \n",
    "    def __n_gram(self, reviews, n):\n",
    "        # default to 1 if not valid length\n",
    "        if (n < 1): n = 1\n",
    "        # generate n-gram on processed reviews where\n",
    "        # a review is ['a', 'list', 'of', 'words']\n",
    "        return [nltk.ngrams(review, n) for review in reviews]\n",
    "\n",
    "feature_generator = MyFeatureGenerator()\n",
    "feature_generator.generateFeatures(x_train, n_gram_len=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" evaluate at least three feature sets with classifier \"\"\"\n",
    "\n",
    "# TODO: CHECK MY FEATURES WORK FOR STANDARD NB IMPLEMENTATION\n",
    "\n",
    "class MyNaiveBayesClassifier:\n",
    "    # for sentiment analysis there will be 3 classes\n",
    "    class_count = 0\n",
    "\n",
    "    def get_prior_probability(self, labels):\n",
    "        # movie review labels is [0(pos), 1(neg), 2(neu), 0, 2, 0, ...]\n",
    "        # array of p(class) where index is class\n",
    "        prior_probs = np.zeros(max(labels) + 1)\n",
    "        self.class_count = len(prior_probs)\n",
    "        for label in labels:\n",
    "            prior_probs[label] += 1/len(labels) #TODO: log(1/len(labels))\n",
    "        \n",
    "        return prior_probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
